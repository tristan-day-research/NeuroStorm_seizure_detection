{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Initialization\n",
        "This project assumes GitHub and Google Cloud Storage info is stored in environmental variables.  \n",
        "It was developed in Google Colab, but can be run locally by selecting 'local' as the environment.  \n",
        "\n",
        "For setup details (including required environment variables), see the README.md in the GitHub repository:  \n",
        "https://github.com/tristan-day-research/NeuroStorm_seizure_detection  "
      ],
      "metadata": {
        "id": "PyY_pxNWgXLq"
      },
      "id": "PyY_pxNWgXLq"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- SETUP GITHUB AND GCP ENVIRONMENT VARIABLES ---\n",
        "# Ensure the following environmental variables are set in Colab user data:\n",
        "# - GITHUB_PAT: GitHub Personal Access Token\n",
        "# - GITHUB_EMAIL: GitHub email for commits\n",
        "# - GITHUB_USER_NAME: GitHub username\n",
        "# - GCP_EEG_PROJECT_ID: Google Cloud Project ID\n",
        "# - GCP_EEG_BUCKET_NAME: (Optional) GCP bucket for EEG data\n",
        "\n",
        "# Select environment\n",
        "ENVIRONMENT = 'colab'   # Choose 'local' or 'colab'\n",
        "BRANCH_NAME = 'main'\n",
        "\n",
        "if ENVIRONMENT == 'colab':\n",
        "    from google.colab import userdata\n",
        "\n",
        "    # Retrieve GitHub credentials from Colab user data\n",
        "    token = userdata.get('GITHUB_PAT')\n",
        "    github_email = userdata.get('GITHUB_EMAIL')\n",
        "    github_username = userdata.get('GITHUB_USER_NAME')\n",
        "\n",
        "    # Clone the repository (done here as the helper file isn't available yet)\n",
        "    !git clone -b {BRANCH_NAME} https://{token}@github.com/tristan-day-research/NeuroStorm_seizure_detection.git\n",
        "\n",
        "    # Change to correct directory\n",
        "    %cd /content/NeuroStorm_seizure_detection/\n",
        "\n",
        "    # Load the helper file now that the repo is cloned\n",
        "    from src.setup import configure_environment\n",
        "\n",
        "    # Run full environment setup\n",
        "    bucket_name = configure_environment(environment=ENVIRONMENT)\n"
      ],
      "metadata": {
        "id": "wFLY5da1Mw8v",
        "outputId": "2cc0fcd3-1e94-44b7-964d-35ee536d9756",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "wFLY5da1Mw8v",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'NeuroStorm_seizure_detection'...\n",
            "remote: Enumerating objects: 172, done.\u001b[K\n",
            "remote: Counting objects: 100% (172/172), done.\u001b[K\n",
            "remote: Compressing objects: 100% (93/93), done.\u001b[K\n",
            "remote: Total 172 (delta 80), reused 156 (delta 69), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (172/172), 1.92 MiB | 10.06 MiB/s, done.\n",
            "Resolving deltas: 100% (80/80), done.\n",
            "/content/NeuroStorm_seizure_detection\n",
            "GCP Project Set\n",
            "Git configured with your user data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Standard Library Imports\n",
        "import os\n",
        "import gc\n",
        "import json\n",
        "import time\n",
        "import glob\n",
        "import math\n",
        "import random\n",
        "import threading\n",
        "import subprocess\n",
        "import logging\n",
        "from collections import OrderedDict\n",
        "from datetime import datetime\n",
        "from functools import partial\n",
        "from warnings import warn\n",
        "\n",
        "# Third-Party Imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import colors\n",
        "plt.rcParams[\"font.family\"] = \"serif\"\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Machine Learning/Deep Learning Imports\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, Subset, random_split\n",
        "from torch.nn.init import trunc_normal_\n",
        "from torch.nn.utils import clip_grad_norm_, rnn\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "from torchvision.transforms import Compose\n",
        "\n",
        "# Check GPU availability\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "PG7sy9nPeNHB",
        "outputId": "2a900c2b-25a2-4d93-c636-fe09d2923f9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "PG7sy9nPeNHB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(bucket_name)"
      ],
      "metadata": {
        "id": "pnfUPO7hc5Ri",
        "outputId": "2c034040-ecfd-4d64-e3a6-8b22c2c606d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "pnfUPO7hc5Ri",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing\n",
        "Each EEG raw signal is segemnted into patches of a fixed length. Fast Fourier Transform (FFT) spectra are made from these patches which will be used to train the Vector-Quantized Variational Autoencoder (VQ-VAE)."
      ],
      "metadata": {
        "id": "3fE92ADGXluH"
      },
      "id": "3fE92ADGXluH"
    },
    {
      "cell_type": "code",
      "source": [
        "# bucket_name = os.getenv('GCP_EEG_BUCKET_NAME')\n",
        "!echo $GCP_EEG_BUCKET_NAME\n",
        "\n",
        "print(bucket_name)"
      ],
      "metadata": {
        "id": "kbj8xSZBbSF_",
        "outputId": "6119a40c-0ad9-4e81-eae3-d99257f2e768",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "kbj8xSZBbSF_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from src.data_and_FFT import EEGDataset\n",
        "\n",
        "# Visualization Function (Separate from Data Loader)\n",
        "def visualize_eeg_and_fft(eeg_tensor, fft_tensor, fft_size, sample_idx=0):\n",
        "    raw_signal = eeg_tensor[sample_idx, :, 0].cpu().numpy()  # [patch_size]\n",
        "    fft_signal = fft_tensor[sample_idx, :, 0].cpu().numpy()  # [fft_size // 2 + 1]\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(raw_signal)\n",
        "    plt.title(\"Raw EEG Signal (Time Domain)\")\n",
        "    plt.xlabel(\"Time\")\n",
        "    plt.ylabel(\"Amplitude\")\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(fft_signal)\n",
        "    plt.title(\"FFT of EEG Signal (Frequency Domain)\")\n",
        "    plt.xlabel(\"Frequency Bin\")\n",
        "    plt.ylabel(\"Magnitude\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Parameters\n",
        "file_prefix = 'kaggle/input/hms-harmful-brain-activity-classification'\n",
        "patch_size = 200\n",
        "overlap = 50\n",
        "fft_size = 256\n",
        "\n",
        "\n",
        "# Load Dataset and Visualize\n",
        "def load_and_visualize_samples(bucket_name, file_prefix, patch_size, overlap, fft_size):\n",
        "    dataset = EEGDataset(\n",
        "        bucket_name=bucket_name,\n",
        "        file_prefix=file_prefix,\n",
        "        patch_size=patch_size,\n",
        "        overlap=overlap,\n",
        "        fft_size=fft_size\n",
        "    )\n",
        "\n",
        "    print(f\"Found {len(dataset)} files. Visualizing...\")\n",
        "\n",
        "    for i in range(min(3, len(dataset))):  # Visualize 3 samples or fewer\n",
        "        fft_data, mask = dataset[i]\n",
        "        visualize_eeg_and_fft(fft_data, fft_data, fft_size)\n",
        "\n",
        "\n",
        "# Run Test\n",
        "load_and_visualize_samples(\n",
        "    bucket_name=bucket_name,\n",
        "    file_prefix=file_prefix,\n",
        "    patch_size=patch_size,\n",
        "    overlap=overlap,\n",
        "    fft_size=fft_size\n",
        ")\n"
      ],
      "metadata": {
        "id": "HN4ytOL4Ypsw"
      },
      "id": "HN4ytOL4Ypsw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenizer"
      ],
      "metadata": {
        "id": "xwTX_KCeklYj"
      },
      "id": "xwTX_KCeklYj"
    },
    {
      "cell_type": "code",
      "source": [
        "from src.vqvae.train import train, validate\n",
        "from src.vqvae.data import EEGDataset, ToPatches\n",
        "from torch.optim import AdamW\n",
        "import torch\n",
        "\n",
        "# --- Hyperparameters ---\n",
        "stride = 150\n",
        "batch_size = 4\n",
        "num_workers = 4\n",
        "num_epochs = 7\n",
        "lr = 1e-4\n",
        "lr_scheduler_step_size = 1\n",
        "lr_scheduler_gamma = 0.9\n",
        "accumulation_steps = 2\n",
        "\n",
        "model_name = \"2025_VQVAE_v1\"\n",
        "codebook_size = 1024\n",
        "emb_dim = 64\n",
        "\n",
        "# --- Dataset and Loader ---\n",
        "transform_to_patches = ToPatches(patch_size=200, stride=stride)\n",
        "eeg_dataset = EEGDataset(bucket_name=BUCKET_NAME, blob_prefix=\"train_eegs_HMS_processed\",\n",
        "                         transform=transform_to_patches)\n",
        "train_size = int(0.8 * len(eeg_dataset))\n",
        "valid_size = len(eeg_dataset) - train_size\n",
        "train_dataset, valid_dataset = random_split(eeg_dataset, [train_size, valid_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
        "\n",
        "# --- Model, Optimizer, Scheduler ---\n",
        "model_class = globals()[model_name]\n",
        "model = model_class(codebook_size=codebook_size, emb_dim=emb_dim)\n",
        "model.to(device)\n",
        "optimizer = AdamW(model.parameters(), lr=lr, weight_decay=1e-3)\n",
        "scheduler = StepLR(optimizer, step_size=lr_scheduler_step_size, gamma=lr_scheduler_gamma)\n",
        "\n",
        "loss_function = partial(fft_masked_mse_loss, phase_start_batch=200, phase_end_batch=400)\n",
        "\n",
        "# --- Train and Validate ---\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
        "    avg_loss = train(model, train_loader, optimizer, loss_function, device,\n",
        "                     scheduler=scheduler, accum_steps=accumulation_steps)\n",
        "    print(f\"Train Loss: {avg_loss:.4f}\")\n",
        "    val_loss = validate(model, valid_loader, loss_function, device)\n",
        "    print(f\"Validation Loss: {val_loss:.4f}\")\n",
        "#\n"
      ],
      "metadata": {
        "id": "90HfgVo8knvO"
      },
      "id": "90HfgVo8knvO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Oeu2dFIGRe-I"
      },
      "id": "Oeu2dFIGRe-I",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}