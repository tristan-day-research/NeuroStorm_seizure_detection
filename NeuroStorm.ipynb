{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Initialization\n",
        "This project assumes GitHub and Google Cloud Storage info is stored in environmental variables. This project was developed in Google Colab. Select either 'colab' or 'local' for the environment.\n",
        "\n",
        "See the README.md in the GitHub repository https://github.com/tristan-day-research/NeuroStorm_seizure_detection for more information on this project and how to use it."
      ],
      "metadata": {
        "id": "PyY_pxNWgXLq"
      },
      "id": "PyY_pxNWgXLq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x40HBrSHYiTl"
      },
      "outputs": [],
      "source": [
        "# _____ IMPORTANT First select envorinment _________\n",
        "\n",
        "ENVIRONMENT = 'colab'   # Choose local or colab\n",
        "BRANCH_NAME = 'main'\n",
        "\n",
        "import os, sys\n",
        "\n",
        "if ENVIRONMENT == 'colab':\n",
        "    from google.colab import userdata\n",
        "\n",
        "    # Retrieve GitHub and GCP credentials from Colab user data\n",
        "    token = userdata.get('GITHUB_PAT')\n",
        "    github_email = userdata.get('GITHUB_EMAIL')\n",
        "    github_username = userdata.get('GITHUB_USER_NAME')\n",
        "\n",
        "    GCP_EEG_PROJECT_ID = userdata.get('GCP_EEG_PROJECT_ID')\n",
        "    BUCKET_NAME = os.getenv('GCP_EEG_BUCKET_NAME')\n",
        "\n",
        "    # Set Git configuration using Python variables\n",
        "    !git config --global user.email \"{github_email}\"\n",
        "    !git config --global user.name \"{github_username}\"\n",
        "\n",
        "    # Clone the repository using the token\n",
        "    !git clone -b {BRANCH_NAME} https://{token}@github.com/tristan-day-research/NeuroStorm_seizure_detection.git\n",
        "\n",
        "    # Change to correct directory\n",
        "    %cd /content/NeuroStorm_seizure_detection/\n",
        "    ! ls\n",
        "    !git status\n",
        "\n",
        "    from google.colab import auth\n",
        "    auth.authenticate_user()\n",
        "\n",
        "    !gcloud auth login\n",
        "    !gcloud config set project {GCP_EEG_PROJECT_ID}\n",
        "\n",
        "\n",
        "if ENVIRONMENT == 'local':\n",
        "   # First clone repository directly via UI\n",
        "\n",
        "    %pip install python-dotenv\n",
        "    from dotenv import load_dotenv\n",
        "    import os\n",
        "\n",
        "    load_dotenv(override=True)\n",
        "\n",
        "\n",
        "    token = os.getenv('GITHUB_PAT')\n",
        "    github_email = os.getenv('GITHUB_EMAIL')\n",
        "    github_username = os.getenv('GITHUB_USER_NAME')\n",
        "\n",
        "    # Set Git configuration using Python variables\n",
        "    !git config --global user.email \"{github_email}\"\n",
        "    !git config --global user.name \"{github_username}\"\n",
        "\n",
        "\n",
        "    !python3 -m ensurepip --upgrade\n",
        "    !python3 -m pip install --upgrade pip\n",
        "\n",
        "    !pip install torch\n",
        "\n",
        "%pip install -r requirements.txt -q\n",
        "os.chdir('/content/NeuroStorm_seizure_detection')\n",
        "\n",
        "\n",
        "# Determine if a GPU is available and set the device accordingly\n",
        "\n",
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "!nvidia-smi  # Display GPU\n"
      ],
      "id": "x40HBrSHYiTl"
    },
    {
      "cell_type": "code",
      "source": [
        "# Standard Library Imports\n",
        "import gc\n",
        "import json\n",
        "import time\n",
        "import glob\n",
        "import math\n",
        "import random\n",
        "import threading\n",
        "import subprocess\n",
        "import logging\n",
        "from collections import OrderedDict\n",
        "from datetime import datetime\n",
        "from functools import partial\n",
        "from warnings import warn\n",
        "\n",
        "# Third-Party Imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import colors\n",
        "plt.rcParams[\"font.family\"] = \"serif\"\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Machine Learning/Deep Learning Imports\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, Subset, random_split\n",
        "from torch.nn.init import trunc_normal_\n",
        "from torch.nn.utils import clip_grad_norm_, rnn\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "from torchvision.transforms import Compose\n"
      ],
      "metadata": {
        "id": "PG7sy9nPeNHB"
      },
      "id": "PG7sy9nPeNHB",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing\n",
        "Each EEG raw signal is segemnted into patches of a fixed length. Fast Fourier Transform (FFT) spectra are made from these patches which will be used to train the Vector-Quantized Variational Autoencoder (VQ-VAE)."
      ],
      "metadata": {
        "id": "3fE92ADGXluH"
      },
      "id": "3fE92ADGXluH"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenizer"
      ],
      "metadata": {
        "id": "xwTX_KCeklYj"
      },
      "id": "xwTX_KCeklYj"
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/NeuroStorm_seizure_detection')"
      ],
      "metadata": {
        "id": "90HfgVo8knvO"
      },
      "id": "90HfgVo8knvO",
      "execution_count": 8,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}